{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import string\n",
    "import csv\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from numpy import *\n",
    "import nltk, nltk.stem.porter\n",
    "import scipy.misc, scipy.io, scipy.optimize\n",
    "from sklearn import svm, model_selection\n",
    "\n",
    "import pylab\n",
    "from matplotlib import pyplot, cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.mlab as mlaba\n",
    "from util import Util\n",
    "\n",
    "EX_DIRECTORY_PATH = './data/'\n",
    "\n",
    "def emailFeatures( word_indices ):\n",
    "    features = zeros((1899, 1))\n",
    "    for index in word_indices:\n",
    "        features[index] = 1\n",
    "    return features\n",
    "\n",
    "def processEmail( email_contents ):\n",
    "    vocab_list = getVocabList()\n",
    "    \n",
    "    word_indices = []\n",
    "    \n",
    "    email_contents = email_contents.lower()\n",
    "    email_contents = re.sub( '<[^<>]+>', ' ', email_contents )\n",
    "    email_contents = re.sub( '[0-9]+', 'number', email_contents )\n",
    "    email_contents = re.sub( '(http|https)://[^\\s]*', 'httpaddr', email_contents )\n",
    "    email_contents = re.sub( '[^\\s]+@[^\\s]+', 'emailaddr', email_contents )\n",
    "    email_contents = re.sub( '[$]+', 'dollar', email_contents )\n",
    "    \n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    tokens = re.split( '[ ' + re.escape(\"@$/#.-:&*+=[]?!(){},'\\\">_<;%\") + ']' , email_contents )\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = re.sub( '[^a-zA-Z0-9]', '', token )\n",
    "        token = stemmer.stem( token.strip() )\n",
    "\n",
    "        if len(token) == 0:\n",
    "            continue\n",
    "\n",
    "        if token in vocab_list:\n",
    "            word_indices.append( vocab_list[token] )\n",
    "            \n",
    "    return word_indices\n",
    "    \n",
    "\n",
    "def getVocabList():\n",
    "    vocab_list = {}\n",
    "    with open( EX_DIRECTORY_PATH + 'vocab.txt', 'r') as file:\n",
    "        reader = csv.reader( file, delimiter='\\t' )\n",
    "        for row in reader:\n",
    "            vocab_list[row[1]] = int(row[0])\n",
    "            \n",
    "    return  vocab_list\n",
    "\n",
    "def part2_1():\n",
    "    email_contents = ''\n",
    "    with open( EX_DIRECTORY_PATH + 'emailSample1.txt', 'r' ) as f:\n",
    "        email_contents = f.read()\n",
    "    \n",
    "    word_indices = processEmail( email_contents )\n",
    "    \n",
    "def part2_2():\n",
    "    email_contents = ''\n",
    "    with open( EX_DIRECTORY_PATH + 'emailSample1.txt', 'r' ) as f:\n",
    "        email_contents = f.read()\n",
    "    \n",
    "    word_indices = processEmail( email_contents )\n",
    "    features      = emailFeatures( word_indices )\n",
    "\n",
    "def part2_3():\n",
    "    mat = scipy.io.loadmat( EX_DIRECTORY_PATH + \"spamTrain.mat\" )\n",
    "    X, y = mat['X'], mat['y']\n",
    "\n",
    "\n",
    "\n",
    "    #linear_svm = svm.SVC(C=0.1, kernel='linear')\n",
    "    #linear_svm.fit( X, y.ravel() )\n",
    "    #pickle.dump( linear_svm, open(\"linear_svm.svm\", \"wb\") )\n",
    "\n",
    "    linear_svm = pickle.load( open(EX_DIRECTORY_PATH + \"linear_svm.svm\", \"rb\") )\n",
    "\n",
    "\n",
    "    predictions = linear_svm.predict( X )\n",
    "    predictions = predictions.reshape( shape(predictions)[0], 1 )\n",
    "    print(( predictions == y ).mean() * 100.0)\n",
    "\n",
    "    mat = scipy.io.loadmat( EX_DIRECTORY_PATH + \"spamTest.mat\" )\n",
    "    X_test, y_test = mat['Xtest'], mat['ytest']\n",
    "\n",
    "    predictions = linear_svm.predict( X_test )\n",
    "    predictions = predictions.reshape( shape(predictions)[0], 1 )\n",
    "    print(( predictions == y_test ).mean() * 100.0)\n",
    "\n",
    "    vocab_list = getVocabList()\n",
    "    reversed_vocab_list = dict( (v, k) for (k, v) in vocab_list.items() )\n",
    "    sorted_indices = argsort( linear_svm.coef_, axis=None )\n",
    "\n",
    "    for i in sorted_indices[0:15]:\n",
    "        print(reversed_vocab_list[i])\n",
    "\n",
    "def part2_4():\n",
    "    mat = scipy.io.loadmat( EX_DIRECTORY_PATH + \"spamTrain.mat\" )\n",
    "    X, y = mat['X'], mat['y']\n",
    "\n",
    "    # linear_svm = pickle.load( open(\"linear_svm.svm\", \"rb\") )\n",
    "    linear_svm = svm.SVC(C=0.1, kernel='linear')\n",
    "    linear_svm.fit( X, y.ravel() )\n",
    "    # pickle.dump( linear_svm, open(\"linear_svm.svm\", \"wb\") )\n",
    "\n",
    "    email_contents = ''\n",
    "    with open( EX_DIRECTORY_PATH + 'spamSample2.txt', 'r' ) as f:\n",
    "        email_contents = f.read()\n",
    "\n",
    "    word_indices = processEmail( email_contents )\n",
    "    features      = emailFeatures( word_indices ).transpose()\n",
    "\n",
    "    print(linear_svm.predict( features ))\n",
    "\n",
    "def main():\n",
    "    set_printoptions(precision=6, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    part2_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    part2_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.825\n",
      "98.9\n",
      "spam\n",
      "that\n",
      "urgent\n",
      "wrong\n",
      "datapow\n",
      "linux\n",
      "round\n",
      "numberth\n",
      "useless\n",
      "unsubscrib\n",
      "august\n",
      "ratio\n",
      "xp\n",
      "toll\n",
      "http\n"
     ]
    }
   ],
   "source": [
    "    part2_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "    part2_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
